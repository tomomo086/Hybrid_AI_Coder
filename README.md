# 🤖 Hybrid_AI_Coder - ハイブリッドAI開発システム

![Platform: Python | LM Studio](https://img.shields.io/badge/Platform-Python%20%7C%20LM%20Studio-green.svg)
![Language: Python](https://img.shields.io/badge/Language-Python-orange.svg)
![AI: Claude4 | ClaudeCode | LM Studio](https://img.shields.io/badge/AI-Claude4%20%7C%20ClaudeCode%20%7C%20LM%20Studio-blue.svg)
![Method: Hybrid AI Development](https://img.shields.io/badge/Method-Hybrid%20AI%20Development-red.svg)
![Status: Active Development](https://img.shields.io/badge/Status-Active%20Development-purple.svg)

> LLMのコンテキスト節約を重視したハイブリッドAI開発システムの実装

**💡 このREADMEの価値**: LLM + SLMの組み合わせによる効率的なコード生成と、コンテキスト消費を劇的に削減する開発手法を実践的に共有

## 🎯 概要・設計意図

**3つの機能だけの究極シンプル設計**：
1. 命令書を受け取る（人間から直接）
2. SLMにコードを生成させる（LM Studio経由）
3. 指定場所にファイル保存（任意パス）

### 💡 設計意図：LLMコンテキスト節約
**メイン目的**: LLM（ClaudeCode・GeminiCLI）の**コンテキスト消費を劇的削減**

- **従来**: LLMがコード生成 → 大量のコンテキスト消費
- **このシステム**: SLMがコード生成 → LLMはコンテキスト節約
- **効果**: LLMは設計・レビューに集中、SLMは実装に特化

### 🔄 SLM随時交換による品質制御
- **DeepSeek-Coder**: 軽量高速、シンプルなコード
- **Qwen2.5-Coder**: 高品質、複雑なロジック対応
- **CodeLlama**: バランス型、汎用性高い
- **即座切り替え**: LM Studio側でモデル変更するだけ

## 🚀 開発フロー

```
人間のアイデア → LLMとの対話 → 要件定義書作成 → 具体的命令書作成 → SLM実行 → 完成コード
```

### 📋 詳細なプロセス

**1. アイデア出し・初期対話**
- **人間**: 「○○のアプリを作りたい」と要求
- **LLM（ClaudeCode/GeminiCLI）**: アイデアの深掘り、課題整理、方向性提案

**2. LLMとの反復対話による要件定義**
- **対話方針**: 納得いくまで反復対話でブラッシュアップ
- **内容**: 機能要件、技術仕様、UI/UX、エラーハンドリング等を詳細化
- **成果物**: 包括的な要件定義書（人間が理解しやすい形式）

**3. SLM向け具体的命令書の作成**
- **LLMとの協働**: 要件定義書をSLMが理解できる具体的な命令に変換
- **重要ポイント**: 
  - **1ファイルレベルの詳細指定**: ファイル構造、関数名、変数名まで明記
  - **具体的な実装方針**: 使用ライブラリ、アルゴリズム、処理フローを明示
  - **エラーハンドリング**: 想定される例外と対処法を明記
  - **コメント指示**: 日本語コメントの内容と配置を詳細指定

**4. SLMでのコード生成**
- **このシステム**: 具体的命令書をLM Studio（SLM）に送信
- **SLM実行**: DeepSeek/Qwen等が命令に従って正確なコード生成
- **結果**: 指定場所にコードが保存

**5. LLMによる修正・最適化**
- **生成後の修正**: SLMが生成したコードの不具合修正
- **要件変更対応**: 追加要件や仕様変更への対応
- **品質向上**: コードの最適化・リファクタリング
- **LLMの役割**: 修正・デバッグ・レビューを担当

## ⚡ 使用方法

このシステムは以下の方法で使用できます：

1. **ClaudeCode/GeminiCLI経由**：プロンプトで命令書と保存先を指定
2. **対話モード**：`ultra_simple.py`を直接実行

## 🛠️ 必要な環境

### 1. AI支援開発環境（いずれか必須）
- **[ClaudeCode](https://claude.ai/code)** - Anthropic公式CLI（推奨）
- **[GeminiCLI](https://ai.google.dev/)** - Google製コマンドライン
- その他AI支援開発ツール

### 2. LM Studio設定（必須）
1. [LM Studio](https://lmstudio.ai/) をダウンロード・起動
2. 推奨モデル（いずれか）を読み込み：
   - **DeepSeek-Coder-6.7B** (軽量・高速)
   - **Qwen2.5-Coder-14B** (高品質・重い)
   - **CodeLlama** (バランス型)
3. ローカルAPIサーバー起動 (http://localhost:1234)

### 3. Python環境
```bash
pip install requests  # 必要なライブラリはこれだけ
```

## 📁 ファイル構成（4ファイルのみ）

```
LLM_SLM_Hybrid_Pair_Programming/
├── ultra_simple.py          # メインシステム（150行）
├── quick_execute.py         # ワンライナー実行（50行）
├── simple_config.json       # SLM接続設定
└── README.md               # このファイル
```

### 設定ファイル
`simple_config.json` が自動作成されます：

```json
{
  "slm_api": {
    "endpoint": "http://localhost:1234/v1/chat/completions"
  }
}
```

**LM Studioでモデル・パラメータを設定** - 設定ファイルにはエンドポイントのみ

## 🔄 実際のワークフロー

```
人間のアイデア → ClaudeCode/GeminiCLI → このシステム → LM Studio → 完成コード
```

## 🎯 システムの特徴

### 💾 コンテキスト節約

#### 基本的な節約効果
- **従来のLLM使用**: コード生成で大量トークン消費
- **このシステム**: SLMが実装担当、LLMは設計に集中
- **効果**: コンテキストを大幅に節約、長時間の開発セッションが可能

#### 現実的な節約効果の詳細
**全体的な節約効果: 20-40%程度**

**節約できる部分**：
- **初回コード生成**: SLMが担当（大幅節約）
- **定型的な実装**: テンプレート的なコード部分

**節約できない部分**：
- **要件定義・対話**: LLMが必要（変わらず）
- **命令書作成**: より詳細な対話が必要（むしろ増加）
- **生成後の修正・デバッグ**: LLMが担当（変わらず〜増加）
- **レビュー・最適化**: LLMが担当（変わらず）

**重要**: 数値的節約より、**LLMを思考・判断に専念させる構造**により開発品質が向上

### 🧠 商用LLM vs SLMの特性理解に基づく最適化

#### 商用LLM（Claude4、GPT-4等）の得意分野
- **抽象的思考**: 要件の曖昧性を自動補完
- **文脈理解**: 長い会話履歴から意図を推測
- **創造的提案**: 新しいアイデアや代替案の提案
- **総合的判断**: 複数要素を考慮した最適解の提示

#### SLM（DeepSeek、Qwen等）の特性
- **具体的指示への高精度**: 明確な命令に対する正確な実行
- **計算コスト効率**: ローカル実行でコスト削減
- **一貫性**: 同じ指示に対する安定した出力
- **専門特化**: コード生成に特化した高い性能

#### この特性差を活かした設計思想
```
商用LLM: 「何を作るか」の企画・設計
    ↓
SLM: 「どう作るか」の具体的実装
```

**重要**: SLMの推論能力制限を具体的指示で補完することで、商用LLM並みの開発品質を実現

### 🔄 SLMによる品質制御
- **リアルタイム切り替え**: LM Studioでワンクリック
- **用途別最適化**: 
  - 軽量タスク → DeepSeek-Coder (高速)
  - 複雑ロジック → Qwen2.5-Coder (高品質)
  - バランス重視 → CodeLlama (汎用)
- **品質実験**: 同じ命令書で複数SLM比較可能

### 🎯 SLM命令書作成のコツ
**商用LLMとSLMの特性差を理解した具体的指示が精度向上の鍵**

- **推論能力の差**: 商用LLM > SLM → 曖昧な指示は避け、具体的に
- **文脈理解の差**: 長い文脈より短い明確な指示を複数に分割
- **技術仕様の明示**: 
  - ❌ 「きれいなコードで」→ ⭕ 「PEP8準拠、関数は30行以内、docstring必須」
  - ❌ 「エラー処理して」→ ⭕ 「FileNotFoundError時は新規作成、ValueError時は再入力促す」
- **実装詳細の指定**:
  - 使用ライブラリのバージョン指定
  - 変数名・関数名の命名規則
  - ファイル構造とディレクトリ配置
  - 日本語コメントの具体的内容

### 🎯 最適な役割分担
- **人間**: 創造性・要件定義・最終判断
- **LLM（ClaudeCode/GeminiCLI）**: 仕様整理・品質管理・レビュー（**コンテキスト節約**）
- **SLM（LM Studio）**: 高速・正確なコード実装

### 🌍 完全日本語対応
- 日本語での要件定義可能
- 日本語コメント付きコード生成
- 日本の開発文化に適応

### ⚡ シンプル設計
- **4ファイルのみ** - 不要な複雑さを排除
- **200行程度** - 全体把握が容易
- **即座に開始** - セットアップ不要
- **簡単操作** - プロンプトで依頼するだけ

## 🚦 システム要件

- **Python 3.7+**
- **requests ライブラリ**
- **LM Studio + 任意のコーディングモデル**
- **ClaudeCode**（推奨） または GeminiCLI

これだけです！

## 📄 ライセンス

このプロジェクトは [MIT License](LICENSE) の下で公開されています。  
商用・非商用問わず自由にご利用ください。

## 📋 開発情報

| **開発者** | tomomo086 + Claude4 |
| **開発期間** | 2025年9月7日 |
| **バージョン** | 1.0.0 |
| **開発ツール** | Claude4, ClaudeCode, LM Studio |

---

## 🔗 関連リンク

- [tomomo086:Github](https://github.com/tomomo086)
- [@mirai_sousiyo39:X](https://x.com/mirai_sousiyo39)

---

**作成者**: [tomomo086(@mirai_sousiyo39) + Claude4]   
**最終更新**: 2025年9月7日

---

**人間の創造性 × AIの実装力 = 効率的な開発スタイル** 🚀

*このREADMEもClaude4、ClaudeCode、LM StudioによるAI支援で作成されています 🤖💻*
