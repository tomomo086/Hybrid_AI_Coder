#!/usr/bin/env python
"""
æ‰‹å‹•data_analyzerå®Ÿè¡Œãƒ†ã‚¹ãƒˆ
Pythonç’°å¢ƒå•é¡Œå›é¿ã®ãŸã‚ã®ç›´æ¥å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

Phase 3ç¶™ç¶š: è¤‡é›‘ãªå‹ãƒ’ãƒ³ãƒˆå¯¾å¿œæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
ID: ed6e1213-1068-42bc-bf7f-0cefea43b0c0
"""

import json
import requests
import time
from pathlib import Path

def load_instruction():
    """data_analyzerå‘½ä»¤æ›¸ã‚’èª­ã¿è¾¼ã¿"""
    instruction_path = Path("data/instructions/ed6e1213-1068-42bc-bf7f-0cefea43b0c0.json")
    
    if not instruction_path.exists():
        print(f"âŒ å‘½ä»¤æ›¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {instruction_path}")
        return None
        
    with open(instruction_path, 'r', encoding='utf-8') as f:
        instruction = json.load(f)
    
    print(f"âœ… å‘½ä»¤æ›¸èª­ã¿è¾¼ã¿å®Œäº†")
    print(f"   ID: {instruction['id']}")
    print(f"   æ©Ÿèƒ½: {instruction['function_name']}")
    print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {instruction['status']}")
    
    return instruction

def create_slm_prompt(instruction):
    """DeepSeek-Coderç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ"""
    req = instruction['requirements']
    
    # å‹ãƒ’ãƒ³ãƒˆæƒ…å ±ã‚’å¼·èª¿
    type_info = []
    for param in req['input']['parameters']:
        type_info.append(f"- {param['name']}: {param['type']} - {param['description']}")
    
    prompt = f"""ã‚ãªãŸã¯å„ªç§€ãªPythonãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ã§ã™ã€‚ä»¥ä¸‹ã®ä»•æ§˜ã«å¾“ã£ã¦é–¢æ•°ã‚’å®Ÿè£…ã—ã¦ãã ã•ã„ã€‚

ã€å®Ÿè£…ã™ã‚‹é–¢æ•°ã€‘
é–¢æ•°å: {instruction['function_name']}

ã€å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå‹ãƒ’ãƒ³ãƒˆé‡è¦ï¼‰ã€‘
{chr(10).join(type_info)}

ã€å‡ºåŠ›ä»•æ§˜ã€‘
- å‹: {req['output']['type']}
- å½¢å¼: {req['output']['format']}
- ä¾‹: {req['output']['example']}

ã€å…¥åŠ›æ¤œè¨¼è¦ä»¶ã€‘
{chr(10).join([f"- {rule}" for rule in req['validation']['input_validation']])}

ã€å‡ºåŠ›æ¤œè¨¼è¦ä»¶ã€‘  
{chr(10).join([f"- {rule}" for rule in req['validation']['output_validation']])}

ã€ä¾å­˜é–¢ä¿‚ã€‘
{chr(10).join([f"- {dep}" for dep in req['dependencies']])}

ã€ã‚³ãƒ¼ãƒ‰ã‚¹ã‚¿ã‚¤ãƒ«è¦ä»¶ã€‘
- {req['style']['coding_standard']}
- Docstring: {req['style']['docstring']}
- å‹ãƒ’ãƒ³ãƒˆ: {req['style']['type_hints']}
- ã‚³ãƒ¡ãƒ³ãƒˆ: {req['style']['comments']}

ã€é‡è¦ã€‘
1. è¤‡é›‘ãªå‹ãƒ’ãƒ³ãƒˆ `List[Dict[str, Union[int, float, str]]]` ã‚’æ­£ç¢ºã«å®Ÿè£…
2. 3ã¤ã®åˆ†æã‚¿ã‚¤ãƒ— (basic_stats, distribution, correlation) ã‚’ã‚µãƒãƒ¼ãƒˆ  
3. å®Œå…¨ãªå‹å®‰å…¨æ€§ã¨ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
4. docstringã¨æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆã‚’å«ã‚€

å®Ÿè£…ã—ã¦ãã ã•ã„ï¼š"""
    
    return prompt

def call_deepseek_api(prompt):
    """LM StudioçµŒç”±ã§DeepSeek-Coder APIå‘¼ã³å‡ºã—"""
    
    # LM Studio APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼‰
    url = "http://localhost:1234/v1/chat/completions"
    
    headers = {
        "Content-Type": "application/json",
    }
    
    data = {
        "model": "local-model",  # LM Studioã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«
        "messages": [
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.1,  # ä½æ¸©åº¦ã§ä¸€è²«æ€§é‡è¦–
        "max_tokens": 2000,  # é•·ã„ã‚³ãƒ¼ãƒ‰ç”Ÿæˆç”¨
        "stream": False
    }
    
    print("ğŸ¤– DeepSeek-Coder APIå‘¼ã³å‡ºã—é–‹å§‹...")
    print(f"   ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: {url}")
    
    try:
        start_time = time.time()
        response = requests.post(url, headers=headers, json=data, timeout=30)
        elapsed_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            generated_code = result['choices'][0]['message']['content']
            
            print(f"âœ… ã‚³ãƒ¼ãƒ‰ç”ŸæˆæˆåŠŸ")
            print(f"   å¿œç­”æ™‚é–“: {elapsed_time:.2f}ç§’")
            print(f"   ç”Ÿæˆæ–‡å­—æ•°: {len(generated_code)}æ–‡å­—")
            
            return generated_code
            
        else:
            print(f"âŒ APIå‘¼ã³å‡ºã—å¤±æ•—")
            print(f"   ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}")
            print(f"   ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {response.text}")
            return None
            
    except requests.exceptions.RequestException as e:
        print(f"âŒ APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ LM StudioãŒèµ·å‹•ã—ã¦DeepSeek-CoderãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„")
        return None

def save_generated_code(instruction_id, generated_code):
    """ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã‚’ä¿å­˜"""
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"data_analyzer_{instruction_id[:8]}_{timestamp}.py"
    output_path = Path("data/generated_code") / filename
    
    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(generated_code)
    
    print(f"âœ… ç”Ÿæˆã‚³ãƒ¼ãƒ‰ä¿å­˜å®Œäº†: {output_path}")
    return output_path

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    print("=" * 60)
    print("ğŸ¤ LLMÃ—SLM data_analyzerå®Ÿè¡Œãƒ†ã‚¹ãƒˆ")
    print("ğŸ¯ Phase 3: è¤‡é›‘ãªå‹ãƒ’ãƒ³ãƒˆå¯¾å¿œæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # Step 1: å‘½ä»¤æ›¸èª­ã¿è¾¼ã¿
    instruction = load_instruction()
    if not instruction:
        return 1
    
    if instruction['status'] != 'approved':
        print(f"âš ï¸ å‘½ä»¤æ›¸ãŒæ‰¿èªã•ã‚Œã¦ã„ã¾ã›ã‚“: {instruction['status']}")
        print("æ‰¿èªå¾Œã«å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return 1
    
    # Step 2: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ
    prompt = create_slm_prompt(instruction)
    print(f"\nğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆå®Œäº† ({len(prompt)}æ–‡å­—)")
    
    # Step 3: DeepSeek-Coderå®Ÿè¡Œ
    generated_code = call_deepseek_api(prompt)
    if not generated_code:
        return 1
    
    # Step 4: ã‚³ãƒ¼ãƒ‰ä¿å­˜
    output_path = save_generated_code(instruction['id'], generated_code)
    
    print(f"\nğŸ‰ data_analyzerå®Ÿè¡Œãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"ğŸ“„ ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«: {output_path}")
    print(f"\nğŸ“‹ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"1. ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®å“è³ªç¢ºèª")
    print(f"2. å®Ÿå‹•ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
    print(f"3. å‹ãƒ’ãƒ³ãƒˆæ¤œè¨¼")
    
    return 0

if __name__ == "__main__":
    exit(main())